# ops/daily_analytics.py
# -*- coding: utf-8 -*-
"""
–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (RU) –¥–ª—è –∫–∞–Ω–∞–ª–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è:
- Google Trends: —Ç–æ–ø-3 —Å—Ç—Ä–∞–Ω—ã –ø–æ –∫–ª—é—á–∞–º (–∑–∞ —Å—É—Ç–∫–∏, now 1-d)
- –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω—ã: —Ç–æ–ø-3 related queries, —Ç–æ–ø –¥–æ–º–µ–Ω—ã (–∏–∑ queries –∏ —Ç–≤–∏—Ç–æ–≤), —Ç–æ–ø —Ö—ç—à—Ç–µ–≥–∏ X
- –í—Å–µ –¥–æ–º–µ–Ω—ã –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–µ (https://<–¥–æ–º–µ–Ω>)
- –ö–Ω–æ–ø–∫–∏ "üìã –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å ‚Äî <—Å—Ç—Ä–∞–Ω–∞>" -> deeplink –≤ –õ–° –±–æ—Ç–∞ /start copy_<ISO2>

ENV:
  TELEGRAM_BOT_TOKEN_APPROVAL  ‚Äî —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ (–∫–æ—Ç–æ—Ä—ã–π –ø–∏—à–µ—Ç –≤ –∫–∞–Ω–∞–ª —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è)
  TELEGRAM_APPROVAL_CHAT_ID    ‚Äî id –∫–∞–Ω–∞–ª–∞/—á–∞—Ç–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è (-100...)
  TELEGRAM_BOT_USERNAME        ‚Äî username –±–æ—Ç–∞ –±–µ–∑ @ (–¥–ª—è deeplink)
"""

import os
import re
import asyncio
import textwrap
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

from telegram import Bot, InlineKeyboardButton, InlineKeyboardMarkup
from pytrends.request import TrendReq
import pycountry

# --- –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (snscrape –º–æ–∂–µ—Ç –ø–∞–¥–∞—Ç—å –≤ CI –∏–∑-–∑–∞ SSL) ---
try:
    import snscrape.modules.twitter as sntwitter
    SNS_OK = True
except Exception:
    SNS_OK = False

# ------------------ ENV ------------------
TOKEN        = os.getenv("TELEGRAM_BOT_TOKEN_APPROVAL")
CHAT_ID      = os.getenv("TELEGRAM_APPROVAL_CHAT_ID")
BOT_USERNAME = os.getenv("TELEGRAM_BOT_USERNAME")  # –±–µ–∑ @

if not TOKEN or not CHAT_ID or not BOT_USERNAME:
    raise SystemExit("Set TELEGRAM_BOT_TOKEN_APPROVAL, TELEGRAM_APPROVAL_CHAT_ID, TELEGRAM_BOT_USERNAME")

# ------------------ –ù–ê–°–¢–†–û–ô–ö–ò ------------------
SEARCH_TERMS      = ["Ai Coin", "AI crypto", "blockchain AI", "$Ai"]
KYIV_TZ           = ZoneInfo("Europe/Kyiv")
MAX_COUNTRIES     = 3
TOP_N_QUERIES     = 3
TW_SAMPLE_LIMIT   = 250  # —Å–∫–æ–ª—å–∫–æ —Ç–≤–∏—Ç–æ–≤ –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–∞–Ω—É
TW_DAYS_WINDOW    = 1    # —Å—É—Ç–∫–∏

DOMAIN_RE = re.compile(r"(?:https?://)?([a-z0-9\-]+(?:\.[a-z0-9\-]+)+)", re.I)

def _extract_domains(text: str) -> list[str]:
    if not text:
        return []
    out = []
    for m in DOMAIN_RE.finditer(text):
        dom = m.group(1).lower().strip(".")
        # –æ—Ç—Å–µ—á—ë–º –º—É—Å–æ—Ä —Ç–∏–ø–∞ t.co, x.com –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å, –Ω–æ t.co ‚Äî –ø–µ—Ä–µ–∞–¥—Ä–µ—Å–∞—Ü–∏—è
        if dom and dom not in {"t.co"}:
            out.append(dom)
    return out

def _iso2_from_name(name: str) -> str | None:
    try:
        # pycountry –∂–¥—ë—Ç —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        if name == "United States":
            name = "United States of America"
        return pycountry.countries.lookup(name).alpha_2
    except Exception:
        return None

def _flag(iso2: str) -> str:
    if not iso2 or len(iso2) != 2:
        return "üåç"
    base = 0x1F1E6
    return "".join(chr(base + ord(c.upper()) - ord('A')) for c in iso2)

def _local_time_label(iso2: str) -> tuple[str, str]:
    # –ø—Ä–æ—Å—Ç–∞—è –∫–∞—Ä—Ç–∞ —á–∞—Å–æ–≤—ã—Ö –ø–æ—è—Å–æ–≤ (–Ω–∞ —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Å—Ç—Ä–∞–Ω—ã)
    tzmap = {
        "UA":"Europe/Kyiv","DE":"Europe/Berlin","TR":"Europe/Istanbul","GB":"Europe/London",
        "US":"America/New_York","CA":"America/Toronto","BR":"America/Sao_Paulo","MX":"America/Mexico_City",
        "AR":"America/Argentina/Buenos_Aires","CL":"America/Santiago",
        "IN":"Asia/Kolkata","ID":"Asia/Jakarta","PH":"Asia/Manila","JP":"Asia/Tokyo",
        "AE":"Asia/Dubai","SA":"Asia/Riyadh","NG":"Africa/Lagos","ZA":"Africa/Johannesburg",
        "AU":"Australia/Sydney"
    }
    tz = ZoneInfo(tzmap.get(iso2, "UTC"))
    now_local = datetime.now(tz).strftime("%Y-%m-%d %H:%M")
    return now_local, tz.key

# ---------------- Google Trends ----------------
def trends_top_countries() -> list[tuple[str, str, int, dict]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: [(country_name, iso2, sum_score, per_term_scores_dict), ...]
    sum_score ‚Äî —Å—É–º–º–∞ –ø–æ –≤—Å–µ–º –∫–ª—é—á–∞–º, per_term_scores: {'Ai Coin': 100, ...}
    """
    py = TrendReq(hl='en-US', tz=0)
    py.build_payload(SEARCH_TERMS, timeframe='now 1-d', geo='', gprop='')
    df = py.interest_by_region(resolution='COUNTRY', inc_low_vol=True)
    if df.empty:
        return []

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∏ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    df = df.fillna(0)
    # —Å—É–º–º–∞—Ä–Ω—ã–π –∏–Ω—Ç–µ—Ä–µ—Å –ø–æ –≤—Å–µ–º –∫–ª—é—á–∞–º
    df['__sum__'] = df.sum(axis=1)
    # –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω—ã, –≥–¥–µ –µ—Å—Ç—å —Ö–æ—Ç—å –∫–∞–∫–æ–π-—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å
    df = df[df['__sum__'] > 0].sort_values('__sum__', ascending=False)

    out = []
    for country_name, row in df.head(12).iterrows():
        iso2 = _iso2_from_name(country_name)
        if not iso2:
            continue
        per_term = {term: int(row.get(term, 0)) for term in SEARCH_TERMS}
        out.append((country_name, iso2, int(row['__sum__']), per_term))
        if len(out) >= 6:
            break
    return out

def related_queries_top(iso2: str, top_n: int = TOP_N_QUERIES) -> list[str]:
    """
    –ë–µ—Ä—ë–º related queries –ø–æ –≤—Å–µ–º –∫–ª—é—á–∞–º –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–∞–Ω—ã iso2 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø‚ÄëN
    –ø–æ —á–∞—Å—Ç–æ—Ç–µ –ø–æ—è–≤–ª–µ–Ω–∏—è/–≤–µ—Å—É (—Å—É–º–º–∏—Ä—É–µ–º 'value' —É top/rising).
    """
    py = TrendReq(hl='en-US', tz=0)
    py.build_payload(SEARCH_TERMS, timeframe='now 1-d', geo=iso2, gprop='')
    rq = py.related_queries()
    q_counter = Counter()

    for _, data in (rq or {}).items():
        if not data:
            continue
        for kind in ("rising", "top"):
            df = data.get(kind)
            if df is None or df.empty:
                continue
            for _, r in df.iterrows():
                q = str(r.get('query') or '').strip()
                if not q:
                    continue
                # Google –æ—Ç–¥–∞—ë—Ç value ~ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –≤–µ—Å
                q_counter[q] += int(r.get('value') or 0)

    top = [q for q, _ in q_counter.most_common(top_n)]
    return top

# ---------------- Twitter (snscrape) ----------------
def twitter_domains_and_tags(country_label: str, limit=TW_SAMPLE_LIMIT) -> tuple[list[str], list[str]]:
    """
    –ò—â–µ–º —Ç–≤–∏—Ç—ã –∑–∞ —Å—É—Ç–∫–∏ –ø–æ –∫–ª—é—á–∞–º + —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ —Ç–≤–∏—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º (—Ç–æ–ø_–¥–æ–º–µ–Ω—ã, —Ç–æ–ø_—Ö—ç—à—Ç–µ–≥–∏)
    """
    if not SNS_OK:
        return [], []

    since_date = (datetime.utcnow() - timedelta(days=TW_DAYS_WINDOW)).date()
    query = f'("Ai Coin" OR "AI crypto" OR "blockchain AI" OR "$Ai") {country_label} since:{since_date}'
    domains = Counter()
    tags = Counter()
    try:
        for i, tw in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):
            if i >= limit:
                break
            content = getattr(tw, "content", "") or ""
            # –¥–æ–º–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ URL
            for d in _extract_domains(content):
                domains[d] += 1
            # –∏–Ω–æ–≥–¥–∞ —Å—Å—ã–ª–∫–∏ –ª–µ–∂–∞—Ç –≤ tw.outlinks
            for u in getattr(tw, "outlinks", []) or []:
                for d in _extract_domains(u):
                    domains[d] += 1
            for tag in (getattr(tw, "hashtags", []) or []):
                t = str(tag).lower().lstrip("#")
                if t:
                    tags[t] += 1
    except Exception:
        # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ SSL/–±–ª–æ–∫–∏ ‚Äî –º–æ–ª—á–∞ –æ—Ç–¥–∞–¥–∏–º –ø—É—Å—Ç—ã–µ
        return [], []

    top_domains = [d for d, _ in domains.most_common(6)]
    top_tags    = [f"#{t}" for t, _ in tags.most_common(6)]
    return top_domains, top_tags

def _linkify(domains: list[str]) -> list[str]:
    """
    –î–µ–ª–∞–µ—Ç –¥–æ–º–µ–Ω—ã –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º–∏: https://<domain>
    """
    out = []
    for d in domains:
        if not d:
            continue
        if not d.startswith("http://") and not d.startswith("https://"):
            out.append(f"https://{d}")
        else:
            out.append(d)
    return out

# ---------------- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ ----------------
def build_message_and_buttons() -> tuple[str, InlineKeyboardMarkup | None]:
    now_kyiv = datetime.now(KYIV_TZ).strftime("%Y-%m-%d %H:%M")
    countries = trends_top_countries()

    # –≤—ã–±–µ—Ä–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ ISO2, –º–∞–∫—Å–∏–º—É–º MAX_COUNTRIES
    picked = []
    seen = set()
    for country_name, iso2, sum_score, per_term in countries:
        if iso2 in seen:
            continue
        picked.append((country_name, iso2, sum_score, per_term))
        seen.add(iso2)
        if len(picked) >= MAX_COUNTRIES:
            break

    lines = [
        f"üìä <b>–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤</b>",
        f"üïí –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {now_kyiv} (–ö–∏–µ–≤)",
        f"üîé –ò—Å—Ç–æ—á–Ω–∏–∫–∏: Google Trends (now 1‚Äëd) + Twitter (snscrape, {TW_DAYS_WINDOW}d)",
        f"üí° –ö–ª—é—á–∏: {', '.join(SEARCH_TERMS)}",
        ""
    ]
    buttons = []

    if not picked:
        lines.append("–î–∞–Ω–Ω—ã—Ö –ø–æ —Å—Ç—Ä–∞–Ω–∞–º —Å–µ–≥–æ–¥–Ω—è –Ω–µ—Ç.")
        return "\n".join(lines), None

    for idx, (country, iso2, sum_score, per_term) in enumerate(picked, 1):
        flag = _flag(iso2)
        local_now, tzkey = _local_time_label(iso2)

        # Google: related queries + –¥–æ–º–µ–Ω—ã –∏–∑ –Ω–∏—Ö
        rq = related_queries_top(iso2, top_n=TOP_N_QUERIES)
        rq_domains = []
        for q in rq:
            rq_domains.extend(_extract_domains(q))
        # —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–º–µ–Ω—ã
        rq_domains = list(dict.fromkeys(rq_domains))

        # Twitter: –¥–æ–º–µ–Ω—ã + —Ç–µ–≥–∏
        tw_domains, tw_tags = twitter_domains_and_tags(country)

        # –°–≤–µ—Å—Ç–∏ –¥–æ–º–µ–Ω—ã –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ (GoogleRQ + Twitter), –æ–±—Ä–µ–∑–∞—Ç—å –¥–æ 5
        combined_domains = list(dict.fromkeys(rq_domains + tw_domains))[:5]
        combined_links = _linkify(combined_domains)
        links_str = ", ".join(f'<a href="{u}">{u.replace("https://","").replace("http://","")}</a>' for u in combined_links) if combined_links else "‚Äî"

        per_terms_str = " ¬∑ ".join(f'{k} ({v})' for k, v in per_term.items() if v > 0) or "‚Äî"
        tags_str = " ".join(tw_tags[:5]) if tw_tags else "#AiCoin #AI #crypto"

        block = textwrap.dedent(f"""\
            {idx}Ô∏è‚É£ {flag} <b>{country}</b>
            üïí –õ–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {local_now} [{tzkey}]
            üìà –ò–Ω—Ç–µ—Ä–µ—Å (–ø–æ –∫–ª—é—á–∞–º): {per_terms_str}
            üìù –¢–æ–ø –∑–∞–ø—Ä–æ—Å—ã (Google): {( " ¬∑ ".join(rq) if rq else "‚Äî" )}
            üåê –°–∞–π—Ç—ã: {links_str}
            üè∑Ô∏è –¢–µ–≥–∏ X: {tags_str}
        """).rstrip()
        lines.append(block)
        lines.append("")  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å

        deeplink = f"https://t.me/{BOT_USERNAME}?start=copy_{iso2}"
        buttons.append([InlineKeyboardButton(f"üìã –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å ‚Äî {country}", url=deeplink)])

    text = "\n".join(lines).strip()
    kb = InlineKeyboardMarkup(buttons) if buttons else None
    return text, kb

# ---------------- –û—Ç–ø—Ä–∞–≤–∫–∞ ----------------
async def send_report():
    bot = Bot(token=TOKEN)
    text, kb = build_message_and_buttons()
    await bot.send_message(
        chat_id=CHAT_ID,
        text=text,
        parse_mode="HTML",
        disable_web_page_preview=False,
        reply_markup=kb
    )

def main():
    asyncio.run(send_report())

if __name__ == "__main__":
    main()