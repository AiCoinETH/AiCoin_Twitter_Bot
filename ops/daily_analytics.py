# -*- coding: utf-8 -*-
"""
–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (RU): –¢–æ–ø-3 —Å—Ç—Ä–∞–Ω—ã –∏–∑ Google Trends –ø–æ —Ç–µ–º–∞–º AiCoin/AI/Crypto,
—Ç–æ–ø-3 –ø–æ–¥–∑–∞–ø—Ä–æ—Å–∞ (related queries), —Ç–æ–ø–æ–≤—ã–µ —Å–∞–π—Ç—ã (–∏–∑ related queries –∏ —Å—Å—ã–ª–æ–∫ –≤ —Ç–≤–∏—Ç–∞—Ö),
–∏ –∫–Ω–æ–ø–∫–∏ "üìã –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å ‚Äî <—Å—Ç—Ä–∞–Ω–∞>" (deeplink –≤ –õ–° –±–æ—Ç–∞).
"""

import os, re, sqlite3, textwrap
from collections import Counter
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

# pip install: pytrends snscrape pycountry babel python-telegram-bot==21.*
from pytrends.request import TrendReq
import pycountry
from babel import Locale
from telegram import Bot, InlineKeyboardButton, InlineKeyboardMarkup

# ------------------ ENV ------------------
TG_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN_APPROVAL")
TG_CHAT  = os.getenv("TELEGRAM_APPROVAL_CHAT_ID")      # -100... –∏–ª–∏ @username
BOT_USER = os.getenv("TELEGRAM_BOT_USERNAME")          # –±–µ–∑ @, –¥–ª—è deeplink
if not (TG_TOKEN and TG_CHAT and BOT_USER):
    raise SystemExit("Set TELEGRAM_BOT_TOKEN_APPROVAL, TELEGRAM_APPROVAL_CHAT_ID, TELEGRAM_BOT_USERNAME")

# –¢–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
TOPICS = ["ai coin", "ai cryptocurrency", "crypto ai", "$ai", "ai+crypto", "ai token"]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
MAX_COUNTRIES = 3        # –¢–û–ü-3 —Å—Ç—Ä–∞–Ω—ã
TOP_N_QUERIES = 3        # –¢–û–ü-3 –ø–æ–¥–∑–∞–ø—Ä–æ—Å–∞/—Ç–µ–º—ã –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–∞–Ω—ã
KYIV_TZ = ZoneInfo("Europe/Kyiv")
PRIME_HOUR = 19          # –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–∞–π–º-—Ç–∞–π–º (—á–∞—Å)
PRIME_MIN  = 30          # –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–∞–π–º-—Ç–∞–π–º (–º–∏–Ω)

# ---------------- SQLite –¥–ª—è ¬´–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å¬ª ----------------
DB = "copy_payloads.db"
def _db_init():
    con = sqlite3.connect(DB)
    con.execute("""
    CREATE TABLE IF NOT EXISTS copy_payloads (
        id TEXT PRIMARY KEY,
        created_at TEXT NOT NULL,
        country TEXT,
        iso2 TEXT,
        payload TEXT NOT NULL
    )""")
    con.commit(); con.close()

def save_copy_payload(copy_id: str, country: str, iso2: str, text: str):
    con = sqlite3.connect(DB)
    con.execute(
        "INSERT OR REPLACE INTO copy_payloads (id, created_at, country, iso2, payload) VALUES (?,?,?,?,?)",
        (copy_id, datetime.utcnow().isoformat()+"Z", country, iso2, text)
    )
    con.commit(); con.close()

# ---------------- –£—Ç–∏–ª–∏—Ç—ã ----------------
def iso2_from_name(name: str) -> str | None:
    try:
        if name == "United States": name = "United States of America"
        return pycountry.countries.lookup(name).alpha_2
    except Exception:
        return None

def flag(iso2: str) -> str:
    if not iso2 or len(iso2)!=2: return "üåç"
    base = 0x1F1E6
    return "".join(chr(base + ord(c.upper()) - ord('A')) for c in iso2)

def local_prime_time(iso2: str):
    tzmap = {
        "UA":"Europe/Kyiv","DE":"Europe/Berlin","TR":"Europe/Istanbul","GB":"Europe/London",
        "US":"America/New_York","CA":"America/Toronto","BR":"America/Sao_Paulo","MX":"America/Mexico_City",
        "IN":"Asia/Kolkata","ID":"Asia/Jakarta","PH":"Asia/Manila","JP":"Asia/Tokyo",
        "AE":"Asia/Dubai","SA":"Asia/Riyadh","NG":"Africa/Lagos","ZA":"Africa/Johannesburg"
    }
    tz = ZoneInfo(tzmap.get(iso2, "UTC"))
    now = datetime.now(tz)
    target = now.replace(hour=PRIME_HOUR, minute=PRIME_MIN, second=0, microsecond=0)
    if target < now:
        target += timedelta(days=1)
    return target, tz

DOMAIN_RE = re.compile(r"(?:https?://)?([a-z0-9\-]+\.[a-z\.]{2,})(?:/|$)", re.I)

def extract_domains(text: str) -> list[str]:
    out = []
    for m in DOMAIN_RE.finditer(text or ""):
        out.append(m.group(1).lower())
    return out

# ---------------- Google Trends ----------------
def trends_top_countries() -> list[tuple[str,int]]:
    py = TrendReq(hl='en-US', tz=0)
    py.build_payload(TOPICS, timeframe='now 7-d', geo='')
    df = py.interest_by_region(resolution='COUNTRY', inc_low_vol=True)
    df['score'] = df.sum(axis=1)
    df = df[df['score']>0].sort_values('score', ascending=False)
    rows = [(name, int(score)) for name, score in df['score'].head(20).items()]
    return rows

def related_queries_top(iso2: str, top_n: int = TOP_N_QUERIES) -> tuple[list[str], list[str]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ç–æ–ø-3 –∑–∞–ø—Ä–æ—Å–æ–≤, —Ç–æ–ø-–¥–æ–º–µ–Ω—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤) –¥–ª—è —Å—Ç—Ä–∞–Ω—ã."""
    py = TrendReq(hl='en-US', tz=0)
    py.build_payload(TOPICS, timeframe='now 7-d', geo=iso2)
    rq = py.related_queries()

    counter = Counter()
    domain_counter = Counter()

    for _, data in (rq or {}).items():
        if not data: continue
        for kind in ("rising", "top"):
            df = data.get(kind)
            if df is None: continue
            for _, row in df.head(10).iterrows():
                q = str(row.get('query') or '').strip()
                if not q: continue
                counter[q] += int(row.get('value') or 0)
                for d in extract_domains(q):
                    domain_counter[d] += 1

    top_queries = [q for q,_ in counter.most_common(top_n)]
    top_domains = [d for d,_ in domain_counter.most_common(3)]
    return top_queries, top_domains

# ---------------- Twitter (snscrape) ----------------
def twitter_domains_and_tags(country_label: str, limit=200) -> tuple[list[str], list[str]]:
    """
    –ë—ã—Å—Ç—Ä—ã–π —Å—ç–º–ø–ª —Ç–≤–∏—Ç–æ–≤: —Å–æ–±–∏—Ä–∞–µ–º –¥–æ–º–µ–Ω—ã —Å—Å—ã–ª–æ–∫ –∏ —Ö—ç—à—Ç–µ–≥–∏.
    –ù–µ —Ç—Ä–µ–±—É–µ—Ç API. –ü–æ–∏—Å–∫ ‚Äì –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ–º–∞–º + –Ω–∞–∑–≤–∞–Ω–∏—é —Å—Ç—Ä–∞–Ω—ã.
    """
    try:
        import snscrape.modules.twitter as sntwitter
    except Exception:
        return [], []

    query = f'("ai coin" OR "ai cryptocurrency" OR "crypto ai" OR "$ai") {country_label} since:{(datetime.utcnow()-timedelta(days=1)).date()}'
    domains = Counter()
    tags = Counter()

    try:
        for i, tw in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):
            if i >= limit: break
            # –¥–æ–º–µ–Ω—ã –∏–∑ —Ç–≤–∏—Ç–∞
            for d in extract_domains(tw.content):
                domains[d] += 1
            # —Ö—ç—à—Ç–µ–≥–∏
            for tag in getattr(tw, "hashtags", []) or []:
                tags[str(tag).lower()] += 1
    except Exception:
        pass

    return [d for d,_ in domains.most_common(5)], [f"#{t}" for t,_ in tags.most_common(5)]

# ---------------- –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å ----------------
def main():
    _db_init()
    bot = Bot(token=TG_TOKEN)

    # 1) —Ç–æ–ø —Å—Ç—Ä–∞–Ω –ø–æ —Ç—Ä–µ–Ω–¥–∞–º
    countries = trends_top_countries()

    # 2) –±–µ—Ä—ë–º –¢–û–ü-3 —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã
    picked = []
    seen = set()
    for name, score in countries:
        iso2 = iso2_from_name(name)
        if not iso2 or iso2 in seen: continue
        picked.append((name, iso2, score))
        seen.add(iso2)
        if len(picked) >= MAX_COUNTRIES: break

    # 3) —Å–æ–±–µ—Ä—ë–º –±–ª–æ–∫–∏ + –∫–Ω–æ–ø–∫–∏
    header = f"üìä –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤ ‚Äî {datetime.now(KYIV_TZ):%Y-%m-%d %H:%M} (–ö–∏–µ–≤)\n–¢–µ–º—ã: {', '.join(TOPICS[:4])}"
    lines = [header, ""]
    keyboard_rows = []

    for idx, (country_name, iso2, score) in enumerate(picked, 1):
        f = flag(iso2)
        local_time, tz = local_prime_time(iso2)

        # Google related queries + –¥–æ–º–µ–Ω—ã
        top_queries, rq_domains = related_queries_top(iso2)

        # Twitter: –¥–æ–º–µ–Ω—ã –∏ —Ç–µ–≥–∏ (–º–∏–Ω–∏-—Å—ç–º–ø–ª –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 24h)
        tw_domains, tw_tags = twitter_domains_and_tags(country_name)

        # –û–±—ä–µ–¥–∏–Ω–∏–º –¥–æ–º–µ–Ω—ã (Trends + Twitter) –∏ –æ—Ç—Å–µ—á—ë–º —à—É–º
        domains = []
        seen_d = set()
        for d in (rq_domains + tw_domains):
            if d in seen_d: continue
            seen_d.add(d); domains.append(d)
        if not domains:
            domains = ["getaicoin.com"]

        # –ë–ª–æ–∫ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∫–∞–Ω–∞–ª
        lines.append(
            textwrap.dedent(f"""\
            {idx}Ô∏è‚É£ {f} <b>{country_name}</b>
            üïí –ü—Ä–∞–π–º-—Ç–∞–π–º (–ª–æ–∫–∞–ª—å–Ω–æ): {local_time:%Y-%m-%d %H:%M} [{tz.key}]
            üìà –¢–æ–ø‚Äë3 —Ç–µ–º—ã (Google): {(' ¬∑ '.join(top_queries) if top_queries else '‚Äî')}
            üåê –ß–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Å–∞–π—Ç—ã: {', '.join(domains[:3])}
            üè∑Ô∏è –•—ç—à—Ç–µ–≥–∏ X: {(' '.join(tw_tags[:3]) if tw_tags else '#AiCoin #AI #crypto')}
            """).rstrip()
        )

        # –¢–µ–∫—Å—Ç –¥–ª—è ¬´–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è¬ª –≤ –õ–° (—Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ –ø—Ä–æ—Å–∏–ª: —Å—Ç—Ä–∞–Ω–∞, –≤—Ä–µ–º—è, —Ç–µ–º–∞(—Ç–æ–ø3), —Å–∞–π—Ç)
        copy_text = textwrap.dedent(f"""\
        {f} {country_name}
        –í—Ä–µ–º—è (–ª–æ–∫–∞–ª—å–Ω–æ): {local_time:%Y-%m-%d %H:%M} [{tz.key}]
        –¢–æ–ø‚Äë3 —Ç–µ–º—ã: {(' ¬∑ '.join(top_queries) if top_queries else '‚Äî')}
        –¢–æ–ø —Å–∞–π—Ç—ã: {', '.join(domains[:3])}
        """).strip()

        copy_id = f"{iso2}_{int(local_time.timestamp())}"
        save_copy_payload(copy_id, country_name, iso2, copy_text)

        deeplink = f"https://t.me/{BOT_USER}?start=copy_{copy_id}"
        keyboard_rows.append([InlineKeyboardButton(f"üìã –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å ‚Äî {country_name}", url=deeplink)])

    # 4) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–∞–Ω–∞–ª/–≥—Ä—É–ø–ø—É —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è
    bot.send_message(
        chat_id=TG_CHAT,
        text="\n\n".join(lines),
        parse_mode="HTML",
        disable_web_page_preview=True,
        reply_markup=InlineKeyboardMarkup(keyboard_rows) if keyboard_rows else None
    )

if __name__ == "__main__":
    main()