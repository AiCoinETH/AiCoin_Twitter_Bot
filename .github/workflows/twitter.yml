name: Test Twitter Bot

on:
  workflow_dispatch:
  repository_dispatch:
    types: [telegram-bot-restart]
  schedule:
    - cron: "0 11-13 * * *"   # 14:00, 15:00, 16:00 Kyiv (UTC+3)

jobs:
  test-bot:
    runs-on: ubuntu-latest

    concurrency:
      group: twitter-bot
      cancel-in-progress: true

    env:
      # Telegram
      TELEGRAM_BOT_TOKEN_APPROVAL:  ${{ secrets.TELEGRAM_BOT_TOKEN_APPROVAL }}
      TELEGRAM_APPROVAL_CHAT_ID:    ${{ secrets.TELEGRAM_APPROVAL_CHAT_ID }}
      TELEGRAM_BOT_TOKEN_CHANNEL:   ${{ secrets.TELEGRAM_BOT_TOKEN_CHANNEL }}
      TELEGRAM_CHANNEL_USERNAME_ID: ${{ secrets.TELEGRAM_CHANNEL_USERNAME_ID }}

      # Twitter
      TWITTER_API_KEY:              ${{ secrets.TWITTER_API_KEY }}
      TWITTER_API_SECRET:           ${{ secrets.TWITTER_API_SECRET }}
      TWITTER_ACCESS_TOKEN:         ${{ secrets.TWITTER_ACCESS_TOKEN }}
      TWITTER_ACCESS_TOKEN_SECRET:  ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}
      TWITTER_BEARER_TOKEN:         ${{ secrets.TWITTER_BEARER_TOKEN }}

      # GitHub (–∞–ø–ª–æ–∞–¥ –º–µ–¥–∏–∞)
      ACTION_PAT_GITHUB:            ${{ secrets.ACTION_PAT_GITHUB }}
      ACTION_REPO_GITHUB:           ${{ secrets.ACTION_REPO_GITHUB }}
      ACTION_EVENT_GITHUB:          ${{ secrets.ACTION_EVENT_GITHUB }}
      ACTION_BRANCH:                ${{ vars.ACTION_BRANCH }}
      GH_IMAGES_DIR:                ${{ vars.GH_IMAGES_DIR }}
      GH_VIDEOS_DIR:                ${{ vars.GH_VIDEOS_DIR }}

      # LLM
      OPENAI_API_KEY:               ${{ secrets.OPENAI_API_KEY }}
      GEMINI_API_KEY:               ${{ secrets.GEMINI_API_KEY }}

      # Google Vertex AI
      VERTEX_PROJECT:               ${{ secrets.VERTEX_PROJECT }}   # api-project-756766452273
      VERTEX_LOCATION:              us-central1
      GCP_KEY_JSON:                 ${{ secrets.GCP_KEY_JSON }}

      # –õ–æ–≥–∏
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Show installed packages
        run: pip freeze | sort

      # üîë –ö–ª–∞–¥—ë–º –∫–ª—é—á –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
      - name: Set up Google credentials
        run: |
          printf '%s' "${GCP_KEY_JSON}" > "$HOME/gcp-key.json"
          echo "GOOGLE_APPLICATION_CREDENTIALS=$HOME/gcp-key.json" >> $GITHUB_ENV
          echo "VERTEX_PROJECT=${VERTEX_PROJECT}" >> $GITHUB_ENV
          echo "VERTEX_LOCATION=${VERTEX_LOCATION}" >> $GITHUB_ENV

      # ‚úÖ –¢–µ—Å—Ç: —Å–Ω–∞—á–∞–ª–∞ Imagen 4, –µ—Å–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ ‚Äî –ø—Ä–æ–±—É–µ–º Imagen 3
      - name: Test Vertex AI Imagen access
        run: |
          python - <<'EOF'
          import os, sys
          import vertexai
          from vertexai.preview.vision_models import ImageGenerationModel

          project  = os.getenv("VERTEX_PROJECT")
          location = os.getenv("VERTEX_LOCATION", "us-central1")
          vertexai.init(project=project, location=location)
          print(f"‚úÖ vertexai.init OK | project={project} | location={location}")

          tried = []
          for model_id in ("imagen-4.0-generate-001", "imagen-3.0-generate-001"):
              try:
                  tried.append(model_id)
                  print(f"‚Üí Trying {model_id} ‚Ä¶")
                  model = ImageGenerationModel.from_pretrained(model_id)
                  imgs = model.generate_images(
                      prompt="simple abstract gradient background, no text",
                      number_of_images=1,
                      size="512x384",
                      safety_filter_level="block_few",
                  )
                  if not imgs:
                      raise RuntimeError("Empty response from Imagen")
                  img0 = imgs[0]
                  got = getattr(img0, "image_bytes", None) or getattr(img0, "bytes", None)
                  print(f"‚úÖ {model_id} OK | bytes={len(got) if got else 'n/a'}")
                  break
              except Exception as e:
                  print(f"‚ö†Ô∏è {model_id} failed: {e}")
          else:
              print(f"‚ùå No working Imagen models among: {tried}")
              sys.exit(1)
          EOF

      - name: Run Twitter Bot
        run: python twitter_bot.py